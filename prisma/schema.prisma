// This is a reference schema for Context-RAG
// Users should copy these models to their own schema.prisma
// or use `npx context-rag init` to add them automatically

generator client {
  provider        = "prisma-client-js"
  previewFeatures = ["postgresqlExtensions"]
}

datasource db {
  provider   = "postgresql"
  url        = env("DATABASE_URL")
  extensions = [vector]
}

// ============================================
// Context-RAG Models
// ============================================

/// Stores prompt configurations for different document types
/// Each document type can have multiple versions for A/B testing
model ContextRagPromptConfig {
  id String @id @default(uuid())

  /// Document type identifier (e.g., "Medical", "Legal", "Technical")
  documentType String @map("document_type")

  /// Human-readable name for this configuration
  name String

  /// System prompt used for AI processing
  systemPrompt String @map("system_prompt") @db.Text

  /// Chunking strategy configuration as JSON
  chunkStrategy Json @map("chunk_strategy")

  /// Version number for this document type (incremental)
  version Int @default(1)

  /// Whether this configuration is active
  isActive Boolean @default(true) @map("is_active")

  /// Whether this is the default config for the document type
  isDefault Boolean @default(false) @map("is_default")

  /// Who created this: 'discovery' | 'manual' | user ID
  createdBy String? @map("created_by")

  /// Reason for changes / changelog entry
  changeLog String? @map("change_log")

  createdAt DateTime @default(now()) @map("created_at")
  updatedAt DateTime @updatedAt @map("updated_at")

  /// Related chunks created with this config
  chunks ContextRagChunk[]

  @@unique([documentType, version])
  @@index([documentType, isActive])
  @@map("context_rag_prompt_configs")
}

/// Stores vector chunks for semantic search
model ContextRagChunk {
  id String @id @default(uuid())

  /// Reference to the prompt config used to create this chunk
  promptConfigId String                 @map("prompt_config_id")
  promptConfig   ContextRagPromptConfig @relation(fields: [promptConfigId], references: [id], onDelete: Cascade)

  /// Reference to the source document
  documentId String @map("document_id")

  /// Sequential index of this chunk within the document
  chunkIndex Int @map("chunk_index")

  /// Type of content: TEXT, TABLE, LIST, CODE, HEADING, IMAGE_REF, QUOTE, MIXED
  chunkType String @map("chunk_type")

  /// Plain text content optimized for vector search
  searchContent String @map("search_content") @db.Text

  /// Vector embedding (768 dimensions for Gemini)
  searchVector Unsupported("vector(768)") @map("search_vector")

  /// Rich Markdown content for display
  displayContent String @map("display_content") @db.Text

  /// Starting page number in source document
  sourcePageStart Int @map("source_page_start")

  /// Ending page number in source document
  sourcePageEnd Int @map("source_page_end")

  /// Confidence score from AI processing (0.0 - 1.0)
  confidenceScore Float @default(0.5) @map("confidence_score")

  /// Additional metadata as JSON
  /// { page, pageRange, type, confidence, tokens, keywords, ... }
  metadata Json

  createdAt DateTime @default(now()) @map("created_at")

  @@index([promptConfigId])
  @@index([documentId])
  @@index([chunkType])
  @@index([confidenceScore])
  @@map("context_rag_chunks")
}

/// Tracks document processing state
model ContextRagDocument {
  id String @id @default(uuid())

  /// Original filename
  filename String

  /// SHA-256 hash for deduplication
  fileHash String @unique @map("file_hash")

  /// File size in bytes
  fileSize Int @map("file_size")

  /// Total page count
  pageCount Int @map("page_count")

  /// Document type (matches PromptConfig.documentType)
  documentType String? @map("document_type")

  /// Processing status: PENDING, DISCOVERING, AWAITING_APPROVAL, PROCESSING, COMPLETED, FAILED, PARTIAL
  status String @default("PENDING")

  /// Reference to prompt config used for processing
  promptConfigId String? @map("prompt_config_id")

  /// Batch processing statistics
  totalBatches     Int @default(0) @map("total_batches")
  completedBatches Int @default(0) @map("completed_batches")
  failedBatches    Int @default(0) @map("failed_batches")

  /// Total token usage as JSON { input, output, total }
  tokenUsage Json? @map("token_usage")

  /// Total processing time in milliseconds
  processingMs Int? @map("processing_ms")

  /// Error message if failed
  errorMessage String? @map("error_message")

  createdAt   DateTime  @default(now()) @map("created_at")
  completedAt DateTime? @map("completed_at")

  /// Related batch jobs
  batches ContextRagBatch[]

  @@index([status])
  @@index([fileHash])
  @@index([documentType])
  @@map("context_rag_documents")
}

/// Tracks individual batch processing jobs
model ContextRagBatch {
  id String @id @default(uuid())

  /// Reference to parent document
  documentId String             @map("document_id")
  document   ContextRagDocument @relation(fields: [documentId], references: [id], onDelete: Cascade)

  /// Sequential batch index (0-based)
  batchIndex Int @map("batch_index")

  /// Starting page of this batch
  pageStart Int @map("page_start")

  /// Ending page of this batch
  pageEnd Int @map("page_end")

  /// Batch status: PENDING, PROCESSING, RETRYING, COMPLETED, FAILED
  status String @default("PENDING")

  /// Number of retry attempts
  retryCount Int @default(0) @map("retry_count")

  /// Last error message if failed
  lastError String? @map("last_error")

  /// Token usage for this batch as JSON
  tokenUsage Json? @map("token_usage")

  /// Processing time in milliseconds
  processingMs Int? @map("processing_ms")

  startedAt   DateTime? @map("started_at")
  completedAt DateTime? @map("completed_at")
  createdAt   DateTime  @default(now()) @map("created_at")
  updatedAt   DateTime  @updatedAt @map("updated_at")

  @@unique([documentId, batchIndex])
  @@index([documentId, status])
  @@index([status])
  @@map("context_rag_batches")
}
